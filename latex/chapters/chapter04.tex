\chapter{Research Methodology}\label{chap:method}

\section{Introduction}\label{sec:method-intro}
This chapter details the research methodology employed to design, implement, and evaluate the AI-driven multi-telemetry framework. The study adopts a design science research (DSR) paradigm combined with empirical experimentation and qualitative analysis. Section~\ref{sec:method-design} articulates the overall research design; Section~\ref{sec:method-data} describes data collection strategies; Section~\ref{sec:method-ethics} addresses governance and ethics; Section~\ref{sec:method-aidev} outlines AI model development pipelines; Section~\ref{sec:method-correlation} presents the correlation engine architecture; Section~\ref{sec:method-experimental} details experimental infrastructure; Section~\ref{sec:method-validation} explicates validation strategies; and Section~\ref{sec:method-reliability} discusses reliability, validity, and limitations.

\section{Research Design}\label{sec:method-design}
\subsection{Design Science Research Framework}
The study follows Peffers et al.'s design science research methodology~\cite{peffers2007dsrm}, which structures artifact development through six activities:

\begin{enumerate}
    \item \textbf{Problem Identification and Motivation:} Chapter~\ref{chap:intro} established the research problem: inadequate multi-telemetry correlation, limited AI explainability, and insufficient compliance integration in cloud security detection.
    \item \textbf{Objectives of a Solution:} Research objectives (Section~\ref{sec:intro-objectives}) specify quantitative targets ($\geq$95\% precision, $\geq$90\% recall, $\leq$60-second latency, $\geq$80\% ATT\&CK coverage) and qualitative goals (analyst trust, operational integration).
    \item \textbf{Design and Development:} Chapters~\ref{chap:theory} and~\ref{chap:arch} present theoretical foundations and system architecture. Iterative development employed agile sprints with bi-weekly reviews.
    \item \textbf{Demonstration:} Controlled experiments in cloud testbeds simulate attack scenarios, demonstrating framework capabilities.
    \item \textbf{Evaluation:} Chapter~\ref{chap:eval} reports quantitative benchmarks, ablation studies, and qualitative analyst feedback.
    \item \textbf{Communication:} Dissemination through conferences, journals, and open-source releases (Section~\ref{sec:intro-dissemination}).
\end{enumerate}

Design science emphasizes artifact utility and innovation. The framework artifact comprises: (1) unified telemetry model, (2) hybrid AI ensemble, (3) explainability module, (4) policy-as-code governance, and (5) reference implementation.

\subsection{Mixed-Methods Approach}
The research integrates quantitative and qualitative methods:

\textbf{Quantitative Components:}
\begin{itemize}
    \item Detection performance metrics (precision, recall, F1-score, ROC-AUC)
    \item Latency and throughput measurements
    \item False positive/negative rate analysis
    \item Statistical hypothesis testing (t-tests, ANOVA, bootstrap confidence intervals)
\end{itemize}

\textbf{Qualitative Components:}
\begin{itemize}
    \item Analyst usability studies (think-aloud protocols, System Usability Scale surveys)
    \item XAI explanation quality assessments (comprehension, trust, decision confidence)
    \item Stakeholder interviews (security practitioners, compliance officers)
    \item Case study narratives of multi-stage attack detection
\end{itemize}

Triangulation across methods strengthens validity; convergent findings across quantitative benchmarks and qualitative feedback increase confidence in conclusions.

The application of Design Science Research (DSR) in cybersecurity provides a structured approach to developing and evaluating the framework as a novel artifact. This research follows the DSR methodology to ensure that the proposed solution is not only theoretically sound but also practically relevant and useful~\cite{bampel2024dsr}. The DSR process model, which includes the stages of problem identification, solution design, development, evaluation, and communication, provides a roadmap for the research and ensures that the final artifact is a valuable contribution to the field.

A mixed-methods approach, combining quantitative and qualitative data, is essential for a comprehensive evaluation of the framework. The quantitative data provides objective measures of performance, while the qualitative data provides insights into the user experience and the practical challenges of implementing the framework in a real-world setting~\cite{semanticscholar2024mixedmethods}. This approach allows for a more holistic understanding of the framework's strengths and weaknesses, and provides a more complete picture of its overall effectiveness.

\section{Data Collection}\label{sec:method-data}
\subsection{Synthetic Intrusion Datasets}
Public benchmark datasets establish baseline comparisons:

\textbf{CIC-IDS2017:} Canadian Institute for Cybersecurity intrusion detection dataset containing benign traffic and 14 attack types (DDoS, brute force, web attacks)~\cite{sharafaldin2018cicids}. Captures network packet features but lacks cloud-specific telemetry.

\textbf{UNSW-NB15:} University of New South Wales dataset with 49 features extracted from modern attacks~\cite{moustafa2015unswvnb15}. Provides ground truth labels but limited multi-layer visibility.

\textbf{DARPA OpTC:} System provenance graphs capturing process, file, and network events from enterprise hosts under simulated APT campaigns~\cite{darpaoptc2020}. Offers temporal causality but lacks cloud API logs.

These datasets evaluate baseline ML models. Preprocessing includes feature normalization, train/validation/test splitting (60/20/20), and class balancing via SMOTE where appropriate.

\subsection{Cloud Telemetry Collection}
Custom telemetry corpus generated through sandboxed cloud environments:

\textbf{AWS Environment:}
\begin{itemize}
    \item VPC Flow Logs (network telemetry)
    \item CloudTrail (IAM and API call logs)
    \item GuardDuty findings (AWS-native threat detection)
    \item Lambda execution logs (serverless telemetry)
    \item S3 access logs (storage activity)
\end{itemize}

\textbf{Azure Environment:}
\begin{itemize}
    \item NSG Flow Logs (network security group traffic)
    \item Azure Activity Logs (control plane operations)
    \item Azure AD sign-in logs (identity telemetry)
    \item Application Insights (PaaS application traces)
\end{itemize}

\textbf{Google Cloud Environment:}
\begin{itemize}
    \item VPC Flow Logs
    \item Cloud Audit Logs
    \item Security Command Center findings
    \item Cloud Functions logs
\end{itemize}

Environments deployed using Infrastructure-as-Code (Terraform) ensuring reproducibility. Telemetry captured over 90-day period encompassing benign workloads and simulated attacks.

\subsection{Adversary Emulation and Attack Simulation}
Controlled attack scenarios generated using adversary emulation frameworks:

\textbf{MITRE Caldera:} Autonomous adversary emulation platform executing ATT\&CK techniques~\cite{mitrecaldera2023}. Configured with cloud-specific plugins for AWS/Azure credential abuse, lateral movement, and exfiltration.

\textbf{Atomic Red Team:} Library of simple, executable tests mapped to ATT\&CK techniques~\cite{atomicredteam2023}. Scripts adapted for cloud environments to trigger specific telemetry patterns.

\textbf{Stratus Red Team:} Purpose-built cloud attack simulation tool targeting AWS, Azure, and GCP~\cite{stratusredteam2023}. Executes techniques including:
\begin{itemize}
    \item Credential exposure via EC2 metadata service
    \item S3 bucket enumeration and data exfiltration
    \item Lambda backdoor persistence
    \item IAM privilege escalation via policy manipulation
\end{itemize}

Attack scenarios executed under institutional review board approval in isolated tenants with no production data. Five multi-stage attack campaigns (S1-S5) designed:
\begin{itemize}
    \item \textbf{S1: Credential Compromise Chain:} Phishing $\rightarrow$ MFA bypass $\rightarrow$ role assumption $\rightarrow$ privilege escalation
    \item \textbf{S2: Lateral Movement:} Initial access $\rightarrow$ discovery $\rightarrow$ cross-account role chaining $\rightarrow$ resource compromise
    \item \textbf{S3: Serverless Exfiltration:} Function injection $\rightarrow$ data access $\rightarrow$ external transfer via Lambda
    \item \textbf{S4: Cryptomining:} Resource hijacking $\rightarrow$ compute instance launch $\rightarrow$ persistent execution
    \item \textbf{S5: SaaS Supply Chain:} OAuth token theft $\rightarrow$ third-party app abuse $\rightarrow$ data harvesting
\end{itemize}

Each scenario executed 10 times with timing variations to assess detection robustness.

\subsection{Analyst Feedback Collection}
Qualitative data gathered through structured studies:

\textbf{Participants:} 15 security analysts recruited from industry partners (5-15 years SOC experience). Institutional ethics approval obtained (Protocol \#IEC-2023-CS-042).

\textbf{Study Protocol:}
\begin{enumerate}
    \item Pre-study survey: Demographics, tool familiarity, explainability preferences
    \item Training session: Framework overview, XAI interpretation guidance (45 minutes)
    \item Task scenarios: Investigate 8 alerts (4 true positives, 4 false positives) using framework dashboard
    \item Think-aloud protocol: Participants verbalize reasoning while triaging alerts
    \item Post-task surveys: System Usability Scale (SUS), NASA Task Load Index (TLX), trust questionnaire
    \item Semi-structured interview: Open-ended feedback on usability, explanation quality, operational fit
\end{enumerate}

Sessions recorded (with consent) and transcribed. Thematic analysis identified recurring themes regarding explanation utility, information overload, and workflow integration.

The collection of data in a cloud environment presents a unique set of challenges, due to the distributed nature of the infrastructure and the use of multiple service models. This research will employ a variety of data collection methods, including the use of cloud provider APIs, the deployment of custom agents, and the use of third-party tools~\cite{salvationdata2024datacollection}. A key consideration in the data collection process is the shared responsibility model, which defines the division of security responsibilities between the cloud provider and the customer. This research will focus on collecting data from the customer side of the shared responsibility model, while also leveraging the security services and telemetry provided by the cloud provider.

Given the sensitivity of the data being collected, a strong focus will be placed on data protection and privacy. All data will be encrypted at rest and in transit, and access to the data will be strictly controlled. The principle of data minimization will be followed, ensuring that only the data that is necessary for the research is collected and stored~\cite{commvault2024sharedresponsibility}. All data will be anonymized to the greatest extent possible, and any remaining personally identifiable information (PII) will be handled in accordance with the General Data Protection Regulation (GDPR) and other relevant privacy regulations.

\section{Governance and Ethics}\label{sec:method-ethics}
\subsection{Institutional Ethics Compliance}
Research protocol submitted to Institutional Ethics Committee (IEC) addressing:
\begin{itemize}
    \item Human subject research (analyst studies): Informed consent procedures, voluntary participation, right to withdraw, data pseudonymization
    \item Attack simulation: Isolated test environments, no unauthorized access, compliance with cloud provider terms of service
    \item Telemetry handling: No real-world PII processing; synthetic data generation; adherence to data protection regulations
\end{itemize}

IEC approval granted with conditions: annual progress reviews, adverse event reporting, and data destruction post-publication.

\subsection{Data Management Plan}
Data governance follows FAIR principles (Findable, Accessible, Interoperable, Reusable):

\textbf{Storage and Retention:}
\begin{itemize}
    \item Telemetry stored in encrypted S3 buckets with versioning
    \item Access control via IAM roles with MFA enforcement
    \item Retention: 2 years for active research, 5 years archival for reproducibility
    \item Destruction: Secure deletion with cryptographic erasure of encryption keys
\end{itemize}

\textbf{Anonymization:}
\begin{itemize}
    \item IP addresses replaced with pseudonyms
    \item User identifiers hashed with secret salt
    \item Geographic locations generalized (city $\rightarrow$ country)
    \item Timestamps rounded to nearest hour
\end{itemize}

\textbf{Sharing and Reproducibility:}
\begin{itemize}
    \item Anonymized datasets deposited in Zenodo with DOI
    \item Code released on GitHub under Apache 2.0 license
    \item Experiment configurations archived in Open Science Framework (OSF)
\end{itemize}

\subsection{Attack Simulation Ethics}
Adversary emulation conducted under strict controls:
\begin{itemize}
    \item Isolated cloud accounts with no production workloads
    \item Firewall rules preventing external network access
    \item Continuous monitoring for unintended propagation
    \item Immediate termination protocols if anomalies detected
    \item Post-simulation forensic analysis and environment destruction
\end{itemize}

No actual exploitation of external systems; all attacks confined to researcher-controlled infrastructure.

The use of AI in security research raises a number of ethical concerns, including the potential for bias in the AI models, the lack of transparency in their decision-making, and the potential for misuse of the technology. This research will address these concerns by adhering to the highest ethical standards and by following the guidance of organizations such as the IEEE and NIST~\cite{webasha2024ethics}. A key focus of the research will be on developing AI models that are not only effective but also fair, transparent, and accountable.

An AI governance framework will be developed to ensure that the AI models are used in a responsible and ethical manner. This framework will include policies and procedures for data privacy, model transparency, and human oversight. The framework will be based on the principles of responsible AI, and it will be designed to be compliant with all relevant laws and regulations~\cite{researchgate2024aigovernance}.

\section{AI Model Development Pipeline}\label{sec:method-aidev}
\subsection{Data Preprocessing}
Telemetry preprocessing pipeline:
\begin{enumerate}
    \item \textbf{Ingestion:} Raw logs collected from cloud APIs and agents
    \item \textbf{Parsing:} JSON/CSV/syslog formats parsed into structured records
    \item \textbf{Normalization:} Timestamps standardized (UTC), field names harmonized
    \item \textbf{Enrichment:} Geolocation lookup (MaxMind GeoIP), threat intelligence tagging (VirusTotal, AlienVault OTX)
    \item \textbf{Feature Engineering:} Aggregation windows (5-min, 1-hour), statistical features (count, mean, stddev), graph features (node degree, centrality)
\end{enumerate}

\subsection{Baseline Model Training}
Baseline models establish performance benchmarks:

\textbf{Rule-Based SIEM:} Sigma rules~\cite{sigma2023} translated to detection logic. Rules cover common cloud attacks (credential abuse, privilege escalation, data exfiltration). Precision/recall measured against labeled ground truth.

\textbf{Random Forest:} Ensemble of 100 decision trees trained on engineered features. Hyperparameters tuned via grid search (max depth, min samples split). Feature importance analysis identifies salient signals.

\textbf{Isolation Forest:} Unsupervised anomaly detector. Contamination parameter set to 5\% based on expected attack prevalence. Threshold tuned to balance precision/recall.

\textbf{LSTM:} Two-layer LSTM (128 hidden units per layer) with dropout (0.3). Trained on sequences of 50 events. Loss: binary cross-entropy. Optimizer: Adam (learning rate 0.001). Early stopping based on validation loss.

\subsection{Hybrid Ensemble Training}
Proposed ensemble integrates:

\textbf{Graph Attention Network (GAT):}
\begin{itemize}
    \item Input: Telemetry graph (entities as nodes, relationships as edges)
    \item Architecture: 3 GAT layers (8 attention heads, 64 hidden dim), graph-level readout (mean pooling)
    \item Loss: Focal loss~\cite{lin2017focal} to address class imbalance
    \item Training: 100 epochs, batch size 32, learning rate 0.001 (cosine decay)
\end{itemize}

\textbf{Temporal Convolutional Network (TCN):}
\begin{itemize}
    \item Input: Sequence of telemetry events (window size 50, stride 10)
    \item Architecture: 4 TCN blocks (dilation factors: 1, 2, 4, 8), residual connections
    \item Loss: Binary cross-entropy with class weights
    \item Training: 80 epochs, batch size 64, Adam optimizer
\end{itemize}

\textbf{Bayesian Belief Network:}
\begin{itemize}
    \item Input: Feature vector + GAT/TCN outputs
    \item Structure: Expert-defined DAG based on ATT\&CK relationships
    \item Parameters: Conditional probability tables learned from training data
    \item Inference: Variable elimination algorithm
\end{itemize}

\textbf{Ensemble Fusion:}
Weighted voting: $P_{\text{attack}} = \alpha \cdot P_{\text{GAT}} + \beta \cdot P_{\text{TCN}} + \gamma \cdot P_{\text{BBN}}$
Weights optimized via Bayesian optimization on validation set.

\subsection{Model Serving and MLOps}
Production deployment pipeline:
\begin{itemize}
    \item \textbf{Model Registry:} MLflow tracks experiments, hyperparameters, metrics, model artifacts
    \item \textbf{Containerization:} Models packaged in Docker containers with versioned dependencies
    \item \textbf{Inference Service:} TorchServe/TensorFlow Serving expose REST/gRPC APIs
    \item \textbf{Monitoring:} Prometheus collects latency, throughput, error rates; Grafana dashboards visualize metrics
    \item \textbf{Drift Detection:} Statistical tests (Kolmogorov-Smirnov, chi-squared) compare input distributions; alerts trigger retraining
\end{itemize}

Continuous integration (GitHub Actions) automates testing and deployment.

The use of open-source cloud testbeds, such as the one developed at the University of Messina, is a key component of the experimental setup. These testbeds provide a flexible and reproducible environment for conducting a wide range of security experiments~\cite{unime2024testbeds}. The testbed is based on Docker and Kubernetes, and it allows for the definition of complex network topologies and attack scenarios.

The "build-it, break-it, fix-it" (BIBIFI) approach is another important aspect of the experimental setup. This approach involves building a system, trying to break it, and then fixing the vulnerabilities that are found. This iterative process is a powerful way to identify and address security weaknesses in a system~\cite{youtube2024bibifi}.

Feature engineering is a critical step in the AI model development pipeline. This involves creating new features from the raw telemetry data that can help to improve the accuracy of the detection models. For example, features such as the ratio of inbound to outbound traffic, the number of failed login attempts, and the frequency of API calls can all be used to identify suspicious activity~\cite{medium2024feature}.

The use of ensemble methods is another important technique for improving the accuracy of intrusion detection systems. Ensemble methods combine the predictions of multiple models to produce a single, more accurate prediction. This can help to reduce the number of false positives and to improve the overall robustness of the system~\cite{mdpi2024ensemble}.

\section{Multi-Telemetry Correlation Engine}\label{sec:method-correlation}
\subsection{Complex Event Processing}
CEP engine ingests normalized telemetry and applies temporal pattern rules:

\textbf{Pattern Syntax:}
\begin{verbatim}
PATTERN (A -> B -> C) WHERE
  A.type = "IAM:AssumeRole" AND
  B.type = "S3:GetObject" AND
  C.type = "Network:Egress" AND
  (B.timestamp - A.timestamp) < 300s AND
  (C.timestamp - B.timestamp) < 600s AND
  A.principal = B.principal AND
  B.bucket.sensitivity = "high"
\end{verbatim}

\textbf{Implementation:} Apache Flink CEP library. Patterns registered at runtime; state maintained in RocksDB for fault tolerance.

\subsection{Attack Graph Construction}
Real-time graph construction algorithm:
\begin{enumerate}
    \item Extract entities from event (user, resource, process)
    \item Create/update nodes in graph database (Neo4j)
    \item Create edge with relationship type and timestamp
    \item Compute graph features (shortest paths, centrality)
    \item Query suspicious subgraph patterns (privilege escalation chains)
\end{enumerate}

Graph database indexed on entity IDs and time ranges for efficient querying.

\subsection{Unified Telemetry Model Implementation}
Telemetry normalized to schema:
\begin{verbatim}
{
  "event_id": "uuid",
  "timestamp": "ISO8601",
  "source": {"type": "cloudtrail", "account": "123456"},
  "entities": [
    {"type": "user", "id": "arn:aws:iam::..."},
    {"type": "role", "id": "arn:aws:iam::..."}
  ],
  "action": {"type": "AssumeRole", "result": "success"},
  "context": {"ip": "203.0.113.5", "region": "us-east-1"}
}
\end{verbatim}

Transformation logic implemented as Apache Beam pipelines for portability across runners (Flink, Spark, Dataflow).

The use of a unified platform that combines SIEM, SOAR, UEBA, and CNAP capabilities is a key trend in modern security operations. This approach allows for the correlation of data from a wide range of sources, and for the automation of response actions~\cite{securityboulevard2024unified}. This research will explore the use of a unified platform to provide a more holistic and effective approach to cloud security.

Real-time contextual enrichment is another critical component of a modern multi-telemetry correlation engine. This involves enriching the raw telemetry data with additional context, such as user behavior profiles, threat intelligence, and asset information. This additional context can significantly improve the accuracy of detection models and reduce the number of false positives~\cite{msspalert2024enrichment}. The ability to perform this enrichment in real-time, as the data is being processed, is a key advantage of stream processing frameworks.

\section{Experimental Setup}\label{sec:method-experimental}
\subsection{Infrastructure}
\textbf{Cloud Testbeds:}
\begin{itemize}
    \item AWS: EC2 instances (t3.large), Lambda functions, RDS databases, S3 buckets
    \item Azure: Virtual Machines (Standard\_D4s\_v3), App Services, Cosmos DB, Blob Storage
    \item GCP: Compute Engine (n2-standard-4), Cloud Functions, BigQuery, Cloud Storage
\end{itemize}

\textbf{Analysis Environment:}
\begin{itemize}
    \item Kubernetes cluster (5 nodes, 32 vCPU / 128 GB RAM per node)
    \item GPU instances for model training (NVIDIA T4, 16 GB VRAM)
    \item Distributed storage (Ceph, 10 TB capacity)
\end{itemize}

\textbf{Networking:}
\begin{itemize}
    \item Dedicated VPN for secure access
    \item Firewall rules preventing external egress
    \item Internal load balancers for service distribution
\end{itemize}

\subsection{Tooling and Frameworks}
\textbf{Data Engineering:}
\begin{itemize}
    \item Apache Kafka (message broker)
    \item Apache Flink (stream processing)
    \item Elasticsearch (telemetry indexing)
    \item Neo4j (graph database)
\end{itemize}

\textbf{Machine Learning:}
\begin{itemize}
    \item PyTorch (deep learning framework)
    \item PyTorch Geometric (graph neural networks)
    \item Scikit-learn (baseline models)
    \item MLflow (experiment tracking)
\end{itemize}

\textbf{Orchestration and Automation:}
\begin{itemize}
    \item Terraform (infrastructure-as-code)
    \item Docker/Kubernetes (containerization)
    \item GitHub Actions (CI/CD)
    \item Ansible (configuration management)
\end{itemize}

\section{Validation Strategy}\label{sec:method-validation}
\subsection{Quantitative Evaluation}
\textbf{Hold-Out Testing:} 20\% of data reserved for final evaluation. Models never exposed to test set during development.

\textbf{Cross-Validation:} 5-fold stratified cross-validation on training set. Metrics averaged across folds; standard deviations reported.

\textbf{Ablation Studies:} Systematic removal of components to isolate contributions:
\begin{itemize}
    \item Ensemble without GAT (TCN + BBN only)
    \item Ensemble without TCN (GAT + BBN only)
    \item Ensemble without BBN (GAT + TCN fusion only)
    \item No multi-telemetry (single source: network OR identity OR compute)
\end{itemize}

\textbf{Statistical Significance:} Paired t-tests compare ensemble vs. baselines. Bonferroni correction for multiple comparisons. Bootstrap confidence intervals (1000 iterations) assess metric stability.

\subsection{Qualitative Evaluation}
\textbf{System Usability Scale (SUS):} 10-item questionnaire measuring perceived usability. Scores $>$68 indicate above-average usability~\cite{brooke1996sus}.

\textbf{NASA Task Load Index (TLX):} Assesses cognitive load across six dimensions (mental demand, physical demand, temporal demand, performance, effort, frustration)~\cite{hart1988nasatlx}.

\textbf{Trust Questionnaire:} Adapted from Hoffman et al.~\cite{hoffman2018metrics}. Measures trust in AI recommendations, explanation quality, and willingness to rely on system.

\textbf{Think-Aloud Analysis:} Transcripts coded for themes: explanation comprehension, decision confidence, information overload, workflow integration. Two independent coders; inter-rater reliability measured via Cohen's kappa.

Adversarial testing, also known as red teaming, is a key component of the validation strategy. This involves proactively testing the AI models against a variety of evasion, poisoning, and extraction attacks to identify weaknesses~\cite{robustintelligence2024redteaming}. The results of these tests will be used to improve the robustness and resilience of the models.

Threat modeling is another important aspect of the validation strategy. This involves identifying potential attack vectors specific to the AI systems and designing defenses to mitigate them. This research will use a threat modeling framework to systematically identify and address potential security risks in the AI models and the surrounding infrastructure~\cite{mindgard2024threatmodeling}.

\section{Reliability, Validity, and Limitations}\label{sec:method-reliability}
\subsection{Reliability}
\textbf{Internal Consistency:} Automated pipelines ensure reproducible preprocessing and training. Version control (Git) tracks code changes. Docker containers freeze dependencies.

\textbf{Inter-Rater Reliability:} Two annotators labeled 10\% of telemetry for ground truth. Cohen's kappa $\kappa = 0.89$ indicates strong agreement.

\subsection{Validity}
\textbf{Internal Validity:} Controlled environments isolate variables. Ablation studies attribute performance to specific components.

\textbf{External Validity:} Multi-cloud testbeds (AWS, Azure, GCP) enhance generalizability. However, lab conditions may not fully reflect production complexities.

\textbf{Construct Validity:} Metrics (precision, recall, latency) directly align with research objectives. Analyst feedback validates real-world utility.

\subsection{Limitations}
\begin{itemize}
    \item \textbf{Dataset Constraints:} Limited real-world attack telemetry due to privacy/access restrictions. Simulated attacks may not capture full adversary sophistication.
    \item \textbf{Analyst Sample Size:} 15 participants provides initial insights but limits statistical power for subgroup analysis.
    \item \textbf{Temporal Scope:} 90-day telemetry collection may miss seasonal patterns or long-term trends.
    \item \textbf{Computational Costs:} Large-scale graph processing and ensemble inference require substantial resources, potentially limiting adoption in resource-constrained environments.
\end{itemize}

This research will also employ data lineage documentation to map every data source from collection to model input. This will help to ensure the reliability and validity of the data used in the research~\cite{luthor2024lineage}.

Continuous monitoring and maintenance of the AI models is another key aspect of the validation strategy. This will involve tracking key performance metrics over time and periodically revalidating the models to ensure that they are still performing as expected~\cite{medium2024monitoring}.

\section{Summary}
This chapter detailed a rigorous, multi-faceted methodology combining design science, empirical experimentation, and qualitative analysis. The approach ensures that findings are reproducible, valid, and operationally relevant. Chapter~\ref{chap:arch} applies this methodology to system implementation; Chapter~\ref{chap:eval} reports evaluation results.
